
뉴런의 작용을 모델링한 신경망은 인공신경망으로도 불린다 (O/X)#O.
맥컬럭은 인간 두뇌를 수많은 뉴런들로 이루어진 잘 정의된 컴퓨터라고 여겼다 (O/X)#O.
신경망은 문자인식, 음성인식, 영상인식, 자연어 처리 등의 분야에 이용되고 있다 (O/X)#O.
XOR 함수는 선형 분리가 가능한 논리함수에 속한다 (O/X)#X.
신경망에서 가장 간단한 노드는 n개의 입력을 받아 n개의 연결강도 벡터들과 각각 곱해진 결과가 합해져서 특정한 활성 함수를 거쳐 출력을 낸다 (O/X)#O.
노드는 내부적인 임계값이나 오프셋 θ, 그리고 비선형 함수의 형태에 따라 그 값이 정해지게 된다 (O/X)#O.
단층 퍼셉트론의 한계점이 노출되면서 2000년대 중반에 다층 퍼셉트론 모델이 제안되었다 (O/X)#X.
신경망은 병렬처리나 학습과 관련된 지능적인 역할을 훌륭하게 수행해낸다 (O/X)#O.
단층 퍼셉트론은 딥러닝의 심층신경망을 거쳐 다층 퍼셉트론으로 발전하였다 (O/X)#X.
신경망에서 계산의 복잡성으로 학습 시간이 너무 오래 걸리는 등의 문제점이 있다 (O/X)#O.
신경망은 인간 두뇌의 생물학적 ()의 작용을 모방하여 고안되었다#뉴런.
신경망에서는 뉴런 사이의 () 조정을 통해 학습이 가능하다#연결강도.
다층 퍼셉트론의 작동은 왕복 운동을 하는 () 학습 알고리즘에 이루어진다#역전파.
다층 퍼셉트론은 입력층, (), 출력층의 순서와 방향으로 연결되어 있다#은닉층.
민스키와 페퍼트는 ()란 저서에서 단층 퍼셉트론의 문제점들을 밝혀냈다#퍼셉트론즈.
마크 I 퍼셉트론은 ()를 인식하는 놀라운 성과에 많은 사람이 환호했다#문자.
()이란 모든 입력 패턴으로부터 얻어지는 출력과 목표 출력과의 오차 제곱의 총합을 최소로 하도록 연결강도를 조정하는 규칙이다#델타규칙.
다층 퍼셉트론에서는 매우 낮은 확률이지만 () 최소점 문제에 봉착할 수 있다#지역.
다음 중 신경망에서 많이 사용되는 비선형 함수가 아닌 것은? 
① 계단함수
② 시그모이드 함수
③ 임계논리 함수
④ 사인 함수#4.
다음 중 선형 분리가 불가능한 논리함수는? 
① AND 함수
② XOR 함수
③ OR 함수
④ NOT 함수#2.
신경망의 획기적인 3가지 모델과 그에 해당하는 알고리즘을 적으시오#로젠블럿의 퍼셉트론 모델(퍼셉트론 알고리즘), PDP 그룹 이후의 다층 퍼셉트론 모델(역전파 알고리즘), 힌턴 이후의 심층신경망(딥러닝 알고리즘).
최초의 학습 규칙은 무엇이고 개발한 인물은 누구인가?#‘헵의 학습 규칙’으로서 1949년 캐나다의 도널드 헵(Hebb)이 제안함.
선형 분리 가능과 특징을 설명하시오#선형 분리 가능이란 패턴 클래스가 하나의 직선에 의해 두 개의 영역으로 나누어지는 것을 말한다, 단층 퍼셉트론은 기본적인 논리 연산인 XOR 함수를 수행해내지 못하고, 선형 분리 가능한 패턴들만을 분류할 수 있는 문제점을 내포하고 있었다.
신경망이 문자인식에 많이 쓰이는 이유와 단점을 기술하시오#신경망이 문자인식에 많이 쓰이는 이유는 신경망이 잡음이나 왜곡, 크기의 다양성, 위치 변화 등에 비교적 잘 적응할 수 있기 때문이다, 그러나 신경망에 의한 문자인식에는 훈련하는데 많은 시간이 걸리는 단점을 가지고 있다.
다층 퍼셉트론에서 역전파 알고리즘을 설명하시오#역전파 알고리즘은 입력층으로부터 은닉층을 거쳐 출력층으로 갔다가, 다시 반대 방향으로 되돌아오면서 학습하므로 역전파란 이름이 붙여졌다, 즉 전방향과 역방향으로 반복적으로 움직이면서 역전파 학습을 하게 된다